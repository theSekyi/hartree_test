{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eebee4d7-8803-493a-bf37-8885432b2016",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:apache_beam.options.pipeline_options:Discarding unparseable args: ['-f', '/Users/emmanuelsekyi/Library/Jupyter/runtime/kernel-9507d57a-5567-414e-9a10-eed482dc691a.json']\n",
      "WARNING:apache_beam.options.pipeline_options:Discarding unparseable args: ['-f', '/Users/emmanuelsekyi/Library/Jupyter/runtime/kernel-9507d57a-5567-414e-9a10-eed482dc691a.json']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/emmanuelsekyi/anaconda3/lib/python3.10/site-packages/pandas/core/indexes/base.py\", line 3802, in get_loc\n",
      "    return self._engine.get_loc(casted_key)\n",
      "  File \"pandas/_libs/index.pyx\", line 138, in pandas._libs.index.IndexEngine.get_loc\n",
      "  File \"pandas/_libs/index.pyx\", line 165, in pandas._libs.index.IndexEngine.get_loc\n",
      "  File \"pandas/_libs/hashtable_class_helper.pxi\", line 5745, in pandas._libs.hashtable.PyObjectHashTable.get_item\n",
      "  File \"pandas/_libs/hashtable_class_helper.pxi\", line 5753, in pandas._libs.hashtable.PyObjectHashTable.get_item\n",
      "KeyError: 'status'\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"apache_beam/runners/common.py\", line 1418, in apache_beam.runners.common.DoFnRunner.process\n",
      "  File \"apache_beam/runners/common.py\", line 625, in apache_beam.runners.common.SimpleInvoker.invoke_process\n",
      "  File \"/Users/emmanuelsekyi/anaconda3/lib/python3.10/site-packages/apache_beam/transforms/core.py\", line -1, in <lambda>\n",
      "  File \"/var/folders/_l/g109827s4sv_6p83rwst2h7h0000gp/T/ipykernel_35507/4100839507.py\", line 9, in compute_aggregations\n",
      "    max_rating = df.groupby(['legal_entity', 'counter_party', 'tier']).agg({'rating': 'max'}).reset_index().rename(columns={'rating': 'max(rating by counterparty)'})\n",
      "  File \"/Users/emmanuelsekyi/anaconda3/lib/python3.10/site-packages/pandas/core/frame.py\", line 3807, in __getitem__\n",
      "    indexer = self.columns.get_loc(key)\n",
      "  File \"/Users/emmanuelsekyi/anaconda3/lib/python3.10/site-packages/pandas/core/indexes/base.py\", line 3804, in get_loc\n",
      "    raise KeyError(key) from err\n",
      "KeyError: 'status'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/emmanuelsekyi/anaconda3/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3460, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/_l/g109827s4sv_6p83rwst2h7h0000gp/T/ipykernel_35507/4100839507.py\", line 48, in <module>\n",
      "    with beam.Pipeline(options=PipelineOptions()) as p:\n",
      "  File \"/Users/emmanuelsekyi/anaconda3/lib/python3.10/site-packages/apache_beam/pipeline.py\", line 600, in __exit__\n",
      "    self.result = self.run()\n",
      "  File \"/Users/emmanuelsekyi/anaconda3/lib/python3.10/site-packages/apache_beam/pipeline.py\", line 577, in run\n",
      "    return self.runner.run_pipeline(self, self._options)\n",
      "  File \"/Users/emmanuelsekyi/anaconda3/lib/python3.10/site-packages/apache_beam/runners/direct/direct_runner.py\", line 131, in run_pipeline\n",
      "    return runner.run_pipeline(pipeline, options)\n",
      "  File \"/Users/emmanuelsekyi/anaconda3/lib/python3.10/site-packages/apache_beam/runners/portability/fn_api_runner/fn_runner.py\", line 202, in run_pipeline\n",
      "    self._latest_run_result = self.run_via_runner_api(\n",
      "  File \"/Users/emmanuelsekyi/anaconda3/lib/python3.10/site-packages/apache_beam/runners/portability/fn_api_runner/fn_runner.py\", line 224, in run_via_runner_api\n",
      "    return self.run_stages(stage_context, stages)\n",
      "  File \"/Users/emmanuelsekyi/anaconda3/lib/python3.10/site-packages/apache_beam/runners/portability/fn_api_runner/fn_runner.py\", line 455, in run_stages\n",
      "    bundle_results = self._execute_bundle(\n",
      "  File \"/Users/emmanuelsekyi/anaconda3/lib/python3.10/site-packages/apache_beam/runners/portability/fn_api_runner/fn_runner.py\", line 783, in _execute_bundle\n",
      "    self._run_bundle(\n",
      "  File \"/Users/emmanuelsekyi/anaconda3/lib/python3.10/site-packages/apache_beam/runners/portability/fn_api_runner/fn_runner.py\", line 1012, in _run_bundle\n",
      "    result, splits = bundle_manager.process_bundle(\n",
      "  File \"/Users/emmanuelsekyi/anaconda3/lib/python3.10/site-packages/apache_beam/runners/portability/fn_api_runner/fn_runner.py\", line 1348, in process_bundle\n",
      "    result_future = self._worker_handler.control_conn.push(process_bundle_req)\n",
      "  File \"/Users/emmanuelsekyi/anaconda3/lib/python3.10/site-packages/apache_beam/runners/portability/fn_api_runner/worker_handlers.py\", line 379, in push\n",
      "    response = self.worker.do_instruction(request)\n",
      "  File \"/Users/emmanuelsekyi/anaconda3/lib/python3.10/site-packages/apache_beam/runners/worker/sdk_worker.py\", line 624, in do_instruction\n",
      "    return getattr(self, request_type)(\n",
      "  File \"/Users/emmanuelsekyi/anaconda3/lib/python3.10/site-packages/apache_beam/runners/worker/sdk_worker.py\", line 662, in process_bundle\n",
      "    bundle_processor.process_bundle(instruction_id))\n",
      "  File \"/Users/emmanuelsekyi/anaconda3/lib/python3.10/site-packages/apache_beam/runners/worker/bundle_processor.py\", line 1062, in process_bundle\n",
      "    input_op_by_transform_id[element.transform_id].process_encoded(\n",
      "  File \"/Users/emmanuelsekyi/anaconda3/lib/python3.10/site-packages/apache_beam/runners/worker/bundle_processor.py\", line 232, in process_encoded\n",
      "    self.output(decoded_value)\n",
      "  File \"apache_beam/runners/worker/operations.py\", line 526, in apache_beam.runners.worker.operations.Operation.output\n",
      "  File \"apache_beam/runners/worker/operations.py\", line 528, in apache_beam.runners.worker.operations.Operation.output\n",
      "  File \"apache_beam/runners/worker/operations.py\", line 237, in apache_beam.runners.worker.operations.SingletonElementConsumerSet.receive\n",
      "  File \"apache_beam/runners/worker/operations.py\", line 240, in apache_beam.runners.worker.operations.SingletonElementConsumerSet.receive\n",
      "  File \"apache_beam/runners/worker/operations.py\", line 907, in apache_beam.runners.worker.operations.DoOperation.process\n",
      "  File \"apache_beam/runners/worker/operations.py\", line 908, in apache_beam.runners.worker.operations.DoOperation.process\n",
      "  File \"apache_beam/runners/common.py\", line 1420, in apache_beam.runners.common.DoFnRunner.process\n",
      "  File \"apache_beam/runners/common.py\", line 1492, in apache_beam.runners.common.DoFnRunner._reraise_augmented\n",
      "  File \"apache_beam/runners/common.py\", line 1418, in apache_beam.runners.common.DoFnRunner.process\n",
      "  File \"apache_beam/runners/common.py\", line 624, in apache_beam.runners.common.SimpleInvoker.invoke_process\n",
      "  File \"apache_beam/runners/common.py\", line 1582, in apache_beam.runners.common._OutputHandler.handle_process_outputs\n",
      "  File \"apache_beam/runners/common.py\", line 1695, in apache_beam.runners.common._OutputHandler._write_value_to_tag\n",
      "  File \"apache_beam/runners/worker/operations.py\", line 240, in apache_beam.runners.worker.operations.SingletonElementConsumerSet.receive\n",
      "  File \"apache_beam/runners/worker/operations.py\", line 907, in apache_beam.runners.worker.operations.DoOperation.process\n",
      "  File \"apache_beam/runners/worker/operations.py\", line 908, in apache_beam.runners.worker.operations.DoOperation.process\n",
      "  File \"apache_beam/runners/common.py\", line 1420, in apache_beam.runners.common.DoFnRunner.process\n",
      "  File \"apache_beam/runners/common.py\", line 1492, in apache_beam.runners.common.DoFnRunner._reraise_augmented\n",
      "  File \"apache_beam/runners/common.py\", line 1418, in apache_beam.runners.common.DoFnRunner.process\n",
      "  File \"apache_beam/runners/common.py\", line 624, in apache_beam.runners.common.SimpleInvoker.invoke_process\n",
      "  File \"apache_beam/runners/common.py\", line 1582, in apache_beam.runners.common._OutputHandler.handle_process_outputs\n",
      "  File \"apache_beam/runners/common.py\", line 1695, in apache_beam.runners.common._OutputHandler._write_value_to_tag\n",
      "  File \"apache_beam/runners/worker/operations.py\", line 240, in apache_beam.runners.worker.operations.SingletonElementConsumerSet.receive\n",
      "  File \"apache_beam/runners/worker/operations.py\", line 907, in apache_beam.runners.worker.operations.DoOperation.process\n",
      "  File \"apache_beam/runners/worker/operations.py\", line 908, in apache_beam.runners.worker.operations.DoOperation.process\n",
      "  File \"apache_beam/runners/common.py\", line 1420, in apache_beam.runners.common.DoFnRunner.process\n",
      "  File \"apache_beam/runners/common.py\", line 1492, in apache_beam.runners.common.DoFnRunner._reraise_augmented\n",
      "  File \"apache_beam/runners/common.py\", line 1418, in apache_beam.runners.common.DoFnRunner.process\n",
      "  File \"apache_beam/runners/common.py\", line 838, in apache_beam.runners.common.PerWindowInvoker.invoke_process\n",
      "  File \"apache_beam/runners/common.py\", line 982, in apache_beam.runners.common.PerWindowInvoker._invoke_process_per_window\n",
      "  File \"apache_beam/runners/common.py\", line 1582, in apache_beam.runners.common._OutputHandler.handle_process_outputs\n",
      "  File \"apache_beam/runners/common.py\", line 1695, in apache_beam.runners.common._OutputHandler._write_value_to_tag\n",
      "  File \"apache_beam/runners/worker/operations.py\", line 240, in apache_beam.runners.worker.operations.SingletonElementConsumerSet.receive\n",
      "  File \"apache_beam/runners/worker/operations.py\", line 907, in apache_beam.runners.worker.operations.DoOperation.process\n",
      "  File \"apache_beam/runners/worker/operations.py\", line 908, in apache_beam.runners.worker.operations.DoOperation.process\n",
      "  File \"apache_beam/runners/common.py\", line 1420, in apache_beam.runners.common.DoFnRunner.process\n",
      "  File \"apache_beam/runners/common.py\", line 1508, in apache_beam.runners.common.DoFnRunner._reraise_augmented\n",
      "  File \"apache_beam/runners/common.py\", line 1418, in apache_beam.runners.common.DoFnRunner.process\n",
      "  File \"apache_beam/runners/common.py\", line 625, in apache_beam.runners.common.SimpleInvoker.invoke_process\n",
      "  File \"/Users/emmanuelsekyi/anaconda3/lib/python3.10/site-packages/apache_beam/transforms/core.py\", line -1, in <lambda>\n",
      "  File \"/var/folders/_l/g109827s4sv_6p83rwst2h7h0000gp/T/ipykernel_35507/4100839507.py\", line 9, in compute_aggregations\n",
      "    max_rating = df.groupby(['legal_entity', 'counter_party', 'tier']).agg({'rating': 'max'}).reset_index().rename(columns={'rating': 'max(rating by counterparty)'})\n",
      "  File \"/Users/emmanuelsekyi/anaconda3/lib/python3.10/site-packages/pandas/core/frame.py\", line 3807, in __getitem__\n",
      "    indexer = self.columns.get_loc(key)\n",
      "  File \"/Users/emmanuelsekyi/anaconda3/lib/python3.10/site-packages/pandas/core/indexes/base.py\", line 3804, in get_loc\n",
      "    raise KeyError(key) from err\n",
      "KeyError: \"status [while running '[11]: Compute aggregations/Map(compute_aggregations)']\"\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/emmanuelsekyi/anaconda3/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 2057, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "  File \"/Users/emmanuelsekyi/anaconda3/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1118, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"/Users/emmanuelsekyi/anaconda3/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1012, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"/Users/emmanuelsekyi/anaconda3/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 865, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "  File \"/Users/emmanuelsekyi/anaconda3/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 818, in format_exception_as_a_whole\n",
      "    frames.append(self.format_record(r))\n",
      "  File \"/Users/emmanuelsekyi/anaconda3/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 736, in format_record\n",
      "    result += ''.join(_format_traceback_lines(frame_info.lines, Colors, self.has_colors, lvals))\n",
      "  File \"/Users/emmanuelsekyi/anaconda3/lib/python3.10/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/Users/emmanuelsekyi/anaconda3/lib/python3.10/site-packages/stack_data/core.py\", line 698, in lines\n",
      "    pieces = self.included_pieces\n",
      "  File \"/Users/emmanuelsekyi/anaconda3/lib/python3.10/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/Users/emmanuelsekyi/anaconda3/lib/python3.10/site-packages/stack_data/core.py\", line 649, in included_pieces\n",
      "    pos = scope_pieces.index(self.executing_piece)\n",
      "  File \"/Users/emmanuelsekyi/anaconda3/lib/python3.10/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/Users/emmanuelsekyi/anaconda3/lib/python3.10/site-packages/stack_data/core.py\", line 628, in executing_piece\n",
      "    return only(\n",
      "  File \"/Users/emmanuelsekyi/anaconda3/lib/python3.10/site-packages/executing/executing.py\", line 164, in only\n",
      "    raise NotOneValueFound('Expected one value, found 0')\n",
      "executing.executing.NotOneValueFound: Expected one value, found 0\n"
     ]
    }
   ],
   "source": [
    "import apache_beam as beam\n",
    "import pandas as pd\n",
    "from apache_beam.options.pipeline_options import PipelineOptions\n",
    "\n",
    "def compute_aggregations(df):\n",
    "    df = pd.DataFrame(df)\n",
    "    arap_sum = df[df['status'] == 'ARAP'].groupby(['legal_entity', 'counter_party', 'tier']).agg({'value': 'sum'}).reset_index().rename(columns={'value': 'sum(value where status=ARAP)'})\n",
    "    accr_sum = df[df['status'] == 'ACCR'].groupby(['legal_entity', 'counter_party', 'tier']).agg({'value': 'sum'}).reset_index().rename(columns={'value': 'sum(value where status=ACCR)'})\n",
    "    max_rating = df.groupby(['legal_entity', 'counter_party', 'tier']).agg({'rating': 'max'}).reset_index().rename(columns={'rating': 'max(rating by counterparty)'})\n",
    "    result = max_rating.merge(arap_sum, on=[\"legal_entity\", \"counter_party\", \"tier\"], how=\"left\").merge(accr_sum, on=[\"legal_entity\", \"counter_party\", \"tier\"], how=\"left\")\n",
    "    result[\"max(rating by counterparty)\"] = result[\"max(rating by counterparty)\"].fillna(0)\n",
    "    result[\"sum(value where status=ARAP)\"] = result[\"sum(value where status=ARAP)\"].fillna(0)\n",
    "    result[\"sum(value where status=ACCR)\"] = result[\"sum(value where status=ACCR)\"].fillna(0)\n",
    "    return result\n",
    "\n",
    "def compute_totals(result):\n",
    "    legal_entity_total = result.groupby(\"legal_entity\").agg({\"max(rating by counterparty)\": \"sum\",\"sum(value where status=ARAP)\": \"sum\",\"sum(value where status=ACCR)\": \"sum\",}).reset_index()\n",
    "    legal_entity_total[\"counter_party\"] = \"Total\"\n",
    "    legal_entity_total[\"tier\"] = \"Total\"\n",
    "\n",
    "    counter_party_total = result.groupby(\"counter_party\").agg({\"max(rating by counterparty)\": \"sum\",\"sum(value where status=ARAP)\": \"sum\",\"sum(value where status=ACCR)\": \"sum\",}).reset_index()\n",
    "    counter_party_total[\"legal_entity\"] = \"Total\"\n",
    "    counter_party_total[\"tier\"] = \"Total\"\n",
    "\n",
    "    tier_total = result.groupby(\"tier\").agg({\"max(rating by counterparty)\": \"sum\",\"sum(value where status=ARAP)\": \"sum\",\"sum(value where status=ACCR)\": \"sum\",}).reset_index()\n",
    "    tier_total[\"legal_entity\"] = \"Total\"\n",
    "    tier_total[\"counter_party\"] = \"Total\"\n",
    "\n",
    "    result = pd.concat([result, legal_entity_total, counter_party_total, tier_total], ignore_index=True)\n",
    "    return result\n",
    "\n",
    "class ComputeAggregations(beam.PTransform):\n",
    "    def expand(self, pcoll):\n",
    "        return pcoll | beam.Map(compute_aggregations)\n",
    "\n",
    "class ComputeTotals(beam.PTransform):\n",
    "    def expand(self, pcoll):\n",
    "        return pcoll | beam.Map(compute_totals)\n",
    "    \n",
    "    \n",
    "def save_to_csv(dataframe):\n",
    "    dataframe.to_csv('../output_data/beam_output.csv', index=False)\n",
    "    \n",
    "\n",
    "def df_to_csv_string(dataframe):\n",
    "    return dataframe.to_csv(index=False)\n",
    "\n",
    "with beam.Pipeline(options=PipelineOptions()) as p:\n",
    "    dataset1 = p | 'Read dataset1' >> beam.io.ReadFromText('../input_data/dataset1.csv', skip_header_lines=1)\n",
    "    dataset2 = p | 'Read dataset2' >> beam.io.ReadFromText('../input_data/dataset2.csv', skip_header_lines=1)\n",
    "\n",
    "    dataset1_df = dataset1 | 'Convert dataset1 to DF' >> beam.Map(lambda line: pd.read_csv(pd.StringIO(line), header=None, names=[\"invoice_id\", \"legal_entity\", \"counter_party\", \"rating\", \"status\", \"value\"]))\n",
    "    dataset2_df = dataset2 | 'Convert dataset2 to DF' >> beam.Map(lambda line: pd.read_csv(pd.StringIO(line), header=None, names=[\"counter_party\", \"tier\"]))\n",
    "\n",
    "    merged_data = ({'d1': dataset1_df, 'd2': dataset2_df}) | 'CoGroupByKey' >> beam.CoGroupByKey() | 'Merge datasets' >> beam.FlatMap(lambda row: pd.merge(pd.DataFrame(row['d1']), pd.DataFrame(row['d2']), on='counter_party', how='left').to_dict('records'))\n",
    "\n",
    "    aggregated_data = merged_data | 'Combine to single DataFrame' >> beam.combiners.ToList() | 'Compute aggregations' >> ComputeAggregations()\n",
    "\n",
    "    with_totals = aggregated_data | 'Compute totals' >> ComputeTotals()\n",
    "\n",
    "    output = with_totals | 'Convert DF to CSV string' >> beam.Map(df_to_csv_string) | 'Save to CSV' >> beam.io.WriteToText('../output_data/beam_output', file_name_suffix='.csv', header='invoice_id,legal_entity,counter_party,rating,status,value,tier,max(rating by counterparty),sum(value where status=ARAP),sum(value where status=ACCR)', num_shards=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "106651be-b4a2-4ffc-b78f-baa8ceb5621a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:apache_beam.options.pipeline_options:Discarding unparseable args: ['-f', '/Users/emmanuelsekyi/Library/Jupyter/runtime/kernel-9507d57a-5567-414e-9a10-eed482dc691a.json']\n",
      "WARNING:apache_beam.options.pipeline_options:Discarding unparseable args: ['-f', '/Users/emmanuelsekyi/Library/Jupyter/runtime/kernel-9507d57a-5567-414e-9a10-eed482dc691a.json']\n",
      "WARNING:apache_beam.io.filebasedsink:No shards found to finalize. num_shards: 1, skipped: 1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import apache_beam as beam\n",
    "import pandas as pd\n",
    "from apache_beam.options.pipeline_options import PipelineOptions\n",
    "\n",
    "\n",
    "def compute_aggregations(df):\n",
    "    arap_sum = (\n",
    "        df[df[\"status\"] == \"ARAP\"]\n",
    "        .groupby([\"legal_entity\", \"counter_party\", \"tier\"])\n",
    "        .agg({\"value\": \"sum\"})\n",
    "        .reset_index()\n",
    "        .rename(columns={\"value\": \"sum(value where status=ARAP)\"})\n",
    "    )\n",
    "    accr_sum = (\n",
    "        df[df[\"status\"] == \"ACCR\"]\n",
    "        .groupby([\"legal_entity\", \"counter_party\", \"tier\"])\n",
    "        .agg({\"value\": \"sum\"})\n",
    "        .reset_index()\n",
    "        .rename(columns={\"value\": \"sum(value where status=ACCR)\"})\n",
    "    )\n",
    "    max_rating = (\n",
    "        df.groupby([\"legal_entity\", \"counter_party\", \"tier\"])\n",
    "        .agg({\"rating\": \"max\"})\n",
    "        .reset_index()\n",
    "        .rename(columns={\"rating\": \"max(rating by counterparty)\"})\n",
    "    )\n",
    "    result = max_rating.merge(arap_sum, on=[\"legal_entity\", \"counter_party\", \"tier\"], how=\"left\").merge(\n",
    "        accr_sum, on=[\"legal_entity\", \"counter_party\", \"tier\"], how=\"left\"\n",
    "    )\n",
    "    result[\"max(rating by counterparty)\"] = result[\"max(rating by counterparty)\"].fillna(0)\n",
    "    result[\"sum(value where status=ARAP)\"] = result[\"sum(value where status=ARAP)\"].fillna(0)\n",
    "    result[\"sum(value where status=ACCR)\"] = result[\"sum(value where status=ACCR)\"].fillna(0)\n",
    "    return result\n",
    "\n",
    "\n",
    "def compute_totals(result):\n",
    "    legal_entity_total = (\n",
    "        result.groupby(\"legal_entity\")\n",
    "        .agg(\n",
    "            {\n",
    "                \"max(rating by counterparty)\": \"sum\",\n",
    "                \"sum(value where status=ARAP)\": \"sum\",\n",
    "                \"sum(value where status=ACCR)\": \"sum\",\n",
    "            }\n",
    "        )\n",
    "        .reset_index()\n",
    "    )\n",
    "    legal_entity_total[\"counter_party\"] = \"Total\"\n",
    "    legal_entity_total[\"tier\"] = \"Total\"\n",
    "\n",
    "    counter_party_total = (\n",
    "        result.groupby(\"counter_party\")\n",
    "        .agg(\n",
    "            {\n",
    "                \"max(rating by counterparty)\": \"sum\",\n",
    "                \"sum(value where status=ARAP)\": \"sum\",\n",
    "                \"sum(value where status=ACCR)\": \"sum\",\n",
    "            }\n",
    "        )\n",
    "        .reset_index()\n",
    "    )\n",
    "    counter_party_total[\"legal_entity\"] = \"Total\"\n",
    "    counter_party_total[\"tier\"] = \"Total\"\n",
    "\n",
    "    tier_total = (\n",
    "        result.groupby(\"tier\")\n",
    "        .agg(\n",
    "            {\n",
    "                \"max(rating by counterparty)\": \"sum\",\n",
    "                \"sum(value where status=ARAP)\": \"sum\",\n",
    "                \"sum(value where status=ACCR)\": \"sum\",\n",
    "            }\n",
    "        )\n",
    "        .reset_index()\n",
    "    )\n",
    "    tier_total[\"legal_entity\"] = \"Total\"\n",
    "    tier_total[\"counter_party\"] = \"Total\"\n",
    "\n",
    "    result = pd.concat([result, legal_entity_total, counter_party_total, tier_total], ignore_index=True)\n",
    "    return result\n",
    "\n",
    "\n",
    "class ComputeAggregations(beam.DoFn):\n",
    "    def process(self, element):\n",
    "        df = pd.DataFrame([element])\n",
    "        return compute_aggregations(df).to_dict(\"records\")\n",
    "\n",
    "\n",
    "class ComputeTotals(beam.DoFn):\n",
    "    def process(self, element):\n",
    "        df = pd.DataFrame([element])\n",
    "        return compute_totals(df).to_dict(\"records\")\n",
    "\n",
    "\n",
    "def save_to_csv(dataframe):\n",
    "    dataframe.to_csv(\"../output_data/beam_output.csv\", index=False)\n",
    "\n",
    "\n",
    "def df_to_csv_string(dataframe):\n",
    "    return dataframe.to_csv(index=False)\n",
    "\n",
    "\n",
    "with beam.Pipeline(options=PipelineOptions()) as p:\n",
    "    dataset1 = p | \"Read dataset1\" >> beam.io.ReadFromText(\"../input_data/dataset1.csv\", skip_header_lines=1)\n",
    "    dataset2 = p | \"Read dataset2\" >> beam.io.ReadFromText(\"../input_data/dataset2.csv\", skip_header_lines=1)\n",
    "\n",
    "    dataset1_df = dataset1 | \"Convert dataset1 to DF\" >> beam.Map(\n",
    "        lambda line: pd.read_csv(\n",
    "            pd.StringIO(line),\n",
    "            header=None,\n",
    "            names=[\"invoice_id\", \"legal_entity\", \"counter_party\", \"rating\", \"status\", \"value\"],\n",
    "        )\n",
    "    )\n",
    "    dataset2_df = dataset2 | \"Convert dataset2 to DF\" >> beam.Map(\n",
    "        lambda line: pd.read_csv(pd.StringIO(line), header=None, names=[\"counter_party\", \"tier\"])\n",
    "    )\n",
    "\n",
    "    merged_data = (\n",
    "        ({\"d1\": dataset1_df, \"d2\": dataset2_df})\n",
    "        | \"CoGroupByKey\" >> beam.CoGroupByKey()\n",
    "        | \"Merge datasets\"\n",
    "        >> beam.FlatMap(\n",
    "            lambda row: pd.merge(\n",
    "                pd.DataFrame(row[\"d1\"]), pd.DataFrame(row[\"d2\"]), on=\"counter_party\", how=\"left\"\n",
    "            ).to_dict(\"records\")\n",
    "        )\n",
    "    )\n",
    "\n",
    "    aggregated_data = merged_data | \"Compute aggregations\" >> beam.ParDo(ComputeAggregations())\n",
    "\n",
    "    with_totals = aggregated_data | \"Compute totals\" >> beam.ParDo(ComputeTotals())\n",
    "\n",
    "    output = (\n",
    "        with_totals\n",
    "        | \"Convert DF to CSV string\" >> beam.Map(df_to_csv_string)\n",
    "        | \"Save to CSV\"\n",
    "        >> beam.io.WriteToText(\n",
    "            \"../output_data/beam_output\",\n",
    "            file_name_suffix=\".csv\",\n",
    "            header=\"invoice_id,legal_entity,counter_party,rating,status,value,tier,max(rating by counterparty),sum(value where status=ARAP),sum(value where status=ACCR)\",\n",
    "            num_shards=1,\n",
    "        )\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "92671b75-6a33-48dc-892f-dcf00f3c942d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "64714fc8-9d4d-4f5f-8986-5bcbc2cdfe91",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:apache_beam.options.pipeline_options:Discarding unparseable args: ['-f', '/Users/emmanuelsekyi/Library/Jupyter/runtime/kernel-9507d57a-5567-414e-9a10-eed482dc691a.json']\n",
      "WARNING:apache_beam.options.pipeline_options:Discarding unparseable args: ['-f', '/Users/emmanuelsekyi/Library/Jupyter/runtime/kernel-9507d57a-5567-414e-9a10-eed482dc691a.json']\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513cbac3-6402-461d-a8ce-bfc6c81f22ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e3777372-9324-4860-9bad-e2d3e09ab45e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:apache_beam.options.pipeline_options:Discarding unparseable args: ['-f', '/Users/emmanuelsekyi/Library/Jupyter/runtime/kernel-9507d57a-5567-414e-9a10-eed482dc691a.json']\n",
      "WARNING:apache_beam.options.pipeline_options:Discarding unparseable args: ['-f', '/Users/emmanuelsekyi/Library/Jupyter/runtime/kernel-9507d57a-5567-414e-9a10-eed482dc691a.json']\n",
      "WARNING:apache_beam.io.filebasedsink:No shards found to finalize. num_shards: 1, skipped: 1\n"
     ]
    }
   ],
   "source": [
    "import apache_beam as beam\n",
    "import pandas as pd\n",
    "from apache_beam.options.pipeline_options import PipelineOptions\n",
    "\n",
    "def compute_aggregations(df):\n",
    "    df = pd.DataFrame(df)\n",
    "    arap_sum = df[df['status'] == 'ARAP'].groupby(['legal_entity', 'counter_party', 'tier']).agg({'value': 'sum'}).reset_index().rename(columns={'value': 'sum(value where status=ARAP)'})\n",
    "    accr_sum = df[df['status'] == 'ACCR'].groupby(['legal_entity', 'counter_party', 'tier']).agg({'value': 'sum'}).reset_index().rename(columns={'value': 'sum(value where status=ACCR)'})\n",
    "    max_rating = df.groupby(['legal_entity', 'counter_party', 'tier']).agg({'rating': 'max'}).reset_index().rename(columns={'rating': 'max(rating by counterparty)'})\n",
    "    result = max_rating.merge(arap_sum, on=[\"legal_entity\", \"counter_party\", \"tier\"], how=\"left\").merge(accr_sum, on=[\"legal_entity\", \"counter_party\", \"tier\"], how=\"left\")\n",
    "    result[\"max(rating by counterparty)\"] = result[\"max(rating by counterparty)\"].fillna(0)\n",
    "    result[\"sum(value where status=ARAP)\"] = result[\"sum(value where status=ARAP)\"].fillna(0)\n",
    "    result[\"sum(value where status=ACCR)\"] = result[\"sum(value where status=ACCR)\"].fillna(0)\n",
    "    return result\n",
    "\n",
    "def compute_totals(result):\n",
    "    legal_entity_total = result.groupby(\"legal_entity\").agg({\"max(rating by counterparty)\": \"sum\",\"sum(value where status=ARAP)\": \"sum\",\"sum(value where status=ACCR)\": \"sum\",}).reset_index()\n",
    "    legal_entity_total[\"counter_party\"] = \"Total\"\n",
    "    legal_entity_total[\"tier\"] = \"Total\"\n",
    "\n",
    "    counter_party_total = result.groupby(\"counter_party\").agg({\"max(rating by counterparty)\": \"sum\",\"sum(value where status=ARAP)\": \"sum\",\"sum(value where status=ACCR)\": \"sum\",}).reset_index()\n",
    "    counter_party_total[\"legal_entity\"] = \"Total\"\n",
    "    counter_party_total[\"tier\"] = \"Total\"\n",
    "\n",
    "    tier_total = result.groupby(\"tier\").agg({\"max(rating by counterparty)\": \"sum\",\"sum(value where status=ARAP)\": \"sum\",\"sum(value where status=ACCR)\": \"sum\",}).reset_index()\n",
    "    tier_total[\"legal_entity\"] = \"Total\"\n",
    "    tier_total[\"counter_party\"] = \"Total\"\n",
    "\n",
    "    result = pd.concat([result, legal_entity_total, counter_party_total, tier_total], ignore_index=True)\n",
    "    return result\n",
    "\n",
    "class ComputeAggregations(beam.PTransform):\n",
    "    def expand(self, pcoll):\n",
    "        return pcoll | beam.Map(compute_aggregations)\n",
    "\n",
    "class ComputeTotals(beam.PTransform):\n",
    "    def expand(self, pcoll):\n",
    "        return pcoll | beam.Map(compute_totals)\n",
    "    \n",
    "    \n",
    "def save_to_csv(dataframe):\n",
    "    dataframe.to_csv('../output_data/beam_output.csv', index=False)\n",
    "    \n",
    "\n",
    "def df_to_csv_string(dataframe):\n",
    "    return dataframe.to_csv(index=False)\n",
    "\n",
    "\n",
    "with beam.Pipeline(options=PipelineOptions()) as p:\n",
    "    dataset1 = p | 'Read dataset1' >> beam.io.ReadFromText('../input_data/dataset1.csv', skip_header_lines=1)\n",
    "    dataset2 = p | 'Read dataset2' >> beam.io.ReadFromText('../input_data/dataset2.csv', skip_header_lines=1)\n",
    "\n",
    "    dataset1_df = dataset1 | 'Convert dataset1 to DF' >> beam.Map(lambda line: pd.DataFrame([dict(zip([\"legal_entity\", \"counter_party\", \"tier\", \"rating\"], line.split(',')))]))\n",
    "    dataset2_df = dataset2 | 'Convert dataset2 to DF' >> beam.Map(lambda line: pd.DataFrame([dict(zip([\"legal_entity\", \"counter_party\", \"tier\", \"status\", \"value\"], line.split(',')))]))\n",
    "\n",
    "    combined_df = (dataset1_df, dataset2_df) | 'Flatten' >> beam.Flatten()\n",
    "    aggregations = combined_df | 'Compute aggregations' >> ComputeAggregations()\n",
    "    totals = aggregations | 'Compute totals' >> ComputeTotals()\n",
    "    csv_string = totals | 'Convert to CSV string' >> beam.Map(df_to_csv_string)\n",
    "    csv_string | 'Write to CSV' >> beam.io.WriteToText('../output_data/beam_output.csv', header=\"legal_entity,counter_party,tier,max(rating by counterparty),sum(value where status=ARAP),sum(value where status=ACCR)\", file_name_suffix='.csv', num_shards=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d36798-06b6-4497-9311-332097d0607b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
